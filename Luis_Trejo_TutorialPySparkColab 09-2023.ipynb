{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbRRaZlBt6Nh"
      },
      "source": [
        "# Tutorial 1: Configuración y carga de datos en PySpark SEP 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6Iv32T_kgRf"
      },
      "source": [
        "##Paso 1: Configuración del entorno de PySpark en Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "sKfMHXDwiZqF",
        "outputId": "13935ccc-b68f-45ed-8ebc-c155aec7c643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\u001b[0m\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 14.2 kB/110 kB 13%] [Waiting for headers]\u001b[0m\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 14.2 kB/110 kB 13%] [Connecting to ppa.la\u001b[0m\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,260 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,283 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 2,772 kB in 2s (1,357 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "19 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.5.0-bin-hadoop3'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Bibliotecas para poder trabajar con Spark\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#!wget -q https://downloads.apache.org/spark/spark-3.2.2/spark-3.2.2-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "#!tar xf spark-3.2.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "#Configuración de Spark con Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "#Estableciendo variable de entorno\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.2-bin-hadoop3.2\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "#Buscando e inicializando la instalación de Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-DE0eskkyRA"
      },
      "source": [
        "##Paso 2: Selección y vista de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ywqxFXoXJiv0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('housing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "jH2hpm6PJYUK",
        "outputId": "1817ecab-fc0c-4b8e-b990-af004aba1f1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20635</th>\n",
              "      <td>-121.09</td>\n",
              "      <td>39.48</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1665.0</td>\n",
              "      <td>374.0</td>\n",
              "      <td>845.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>1.5603</td>\n",
              "      <td>78100.0</td>\n",
              "      <td>INLAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20636</th>\n",
              "      <td>-121.21</td>\n",
              "      <td>39.49</td>\n",
              "      <td>18.0</td>\n",
              "      <td>697.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>356.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>2.5568</td>\n",
              "      <td>77100.0</td>\n",
              "      <td>INLAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20637</th>\n",
              "      <td>-121.22</td>\n",
              "      <td>39.43</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2254.0</td>\n",
              "      <td>485.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>433.0</td>\n",
              "      <td>1.7000</td>\n",
              "      <td>92300.0</td>\n",
              "      <td>INLAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20638</th>\n",
              "      <td>-121.32</td>\n",
              "      <td>39.43</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1860.0</td>\n",
              "      <td>409.0</td>\n",
              "      <td>741.0</td>\n",
              "      <td>349.0</td>\n",
              "      <td>1.8672</td>\n",
              "      <td>84700.0</td>\n",
              "      <td>INLAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20639</th>\n",
              "      <td>-121.24</td>\n",
              "      <td>39.37</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2785.0</td>\n",
              "      <td>616.0</td>\n",
              "      <td>1387.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>2.3886</td>\n",
              "      <td>89400.0</td>\n",
              "      <td>INLAND</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20640 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0        -122.23     37.88                41.0        880.0           129.0   \n",
              "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
              "2        -122.24     37.85                52.0       1467.0           190.0   \n",
              "3        -122.25     37.85                52.0       1274.0           235.0   \n",
              "4        -122.25     37.85                52.0       1627.0           280.0   \n",
              "...          ...       ...                 ...          ...             ...   \n",
              "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
              "20636    -121.21     39.49                18.0        697.0           150.0   \n",
              "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
              "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
              "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \\\n",
              "0           322.0       126.0         8.3252            452600.0   \n",
              "1          2401.0      1138.0         8.3014            358500.0   \n",
              "2           496.0       177.0         7.2574            352100.0   \n",
              "3           558.0       219.0         5.6431            341300.0   \n",
              "4           565.0       259.0         3.8462            342200.0   \n",
              "...           ...         ...            ...                 ...   \n",
              "20635       845.0       330.0         1.5603             78100.0   \n",
              "20636       356.0       114.0         2.5568             77100.0   \n",
              "20637      1007.0       433.0         1.7000             92300.0   \n",
              "20638       741.0       349.0         1.8672             84700.0   \n",
              "20639      1387.0       530.0         2.3886             89400.0   \n",
              "\n",
              "      ocean_proximity  \n",
              "0            NEAR BAY  \n",
              "1            NEAR BAY  \n",
              "2            NEAR BAY  \n",
              "3            NEAR BAY  \n",
              "4            NEAR BAY  \n",
              "...               ...  \n",
              "20635          INLAND  \n",
              "20636          INLAND  \n",
              "20637          INLAND  \n",
              "20638          INLAND  \n",
              "20639          INLAND  \n",
              "\n",
              "[20640 rows x 10 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px0CvEobk43I"
      },
      "source": [
        "## Paso 3: Crear la sesión de trabajo de Spark\n",
        "\n",
        "Ya seleccionado y visto el conjunto de datos comencemos a trabajar con PySpark. Para comenzar a trabajar con PySpark, debemos iniciar la sesión de Spark. Para esto realizaremos lo siguiente:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   Importar SparkSession\n",
        "2.   Crear la sesión\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "hqEN5b1eKRTn",
        "outputId": "19a4dcc3-1c99-424f-f623-1eeaaadaa004"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "your 131072x1 screen size is bogus. expect trouble\n",
            "23/09/22 16:39:09 WARN Utils: Your hostname, Nitro-Andre resolves to a loopback address: 127.0.1.1; using 172.22.45.199 instead (on interface eth0)\n",
            "23/09/22 16:39:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/09/22 16:39:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://172.22.45.199:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_Andre</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f234749cf70>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Verificar la funcionalidad de Pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark_session = SparkSession.builder.appName('PySpark_Andre').getOrCreate()\n",
        "spark_session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbRahpVtmPBu"
      },
      "source": [
        "La SparkSession contiene los siguiente elementos:\n",
        "\n",
        "\n",
        "*   Version: La versión de Spark\n",
        "*   Master: Como estamos trabajando en un sistema en la nube pero no distribuido nos devuelve local, sin embargo, si tuvieramos un sistema distribuido aquí entonces podríamos tener diferentes clústeres, así como primero habrá un maestro y luego una estructura similar a un árbol (cluster_1, cluster_2 ... cluster_n).\n",
        "*   AppName: Nombre de la aplicación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iADBYL1_tvfU"
      },
      "source": [
        "##Paso 4: Cargar los datos para manipularlos dentro de Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJdqDvH1Ke0F",
        "outputId": "1a8480f5-df46-479a-d19a-04f3fe546fe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_spark = spark_session.read.csv('housing.csv')\n",
        "df_spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkNMWmBnm6QO"
      },
      "source": [
        "En el caso de PySpark para visualizar los datos tenemos la función *show()* ques similar a *head()* de pandas con algunas diferencias como:\n",
        "\n",
        "\n",
        "1.   Mostrar 20 registro en lugar de 5\n",
        "2.   La apariencia de los datos\n",
        "3.   En lugar de tomar la primera fila como encabezados la incluye como un registro y coloca _c1 a _cn como nombre de la columna.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT2_YaGFnynL",
        "outputId": "b65eb9af-faf0-4465-bffc-4aadb38b5ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "|      _c0|     _c1|               _c2|        _c3|           _c4|       _c5|       _c6|          _c7|               _c8|            _c9|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
            "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
            "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|\n",
            "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
            "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|\n",
            "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|       NEAR BAY|\n",
            "|  -122.25|   37.85|              52.0|      919.0|         213.0|     413.0|     193.0|       4.0368|          269700.0|       NEAR BAY|\n",
            "|  -122.25|   37.84|              52.0|     2535.0|         489.0|    1094.0|     514.0|       3.6591|          299200.0|       NEAR BAY|\n",
            "|  -122.25|   37.84|              52.0|     3104.0|         687.0|    1157.0|     647.0|         3.12|          241400.0|       NEAR BAY|\n",
            "|  -122.26|   37.84|              42.0|     2555.0|         665.0|    1206.0|     595.0|       2.0804|          226700.0|       NEAR BAY|\n",
            "|  -122.25|   37.84|              52.0|     3549.0|         707.0|    1551.0|     714.0|       3.6912|          261100.0|       NEAR BAY|\n",
            "|  -122.26|   37.85|              52.0|     2202.0|         434.0|     910.0|     402.0|       3.2031|          281500.0|       NEAR BAY|\n",
            "|  -122.26|   37.85|              52.0|     3503.0|         752.0|    1504.0|     734.0|       3.2705|          241800.0|       NEAR BAY|\n",
            "|  -122.26|   37.85|              52.0|     2491.0|         474.0|    1098.0|     468.0|        3.075|          213500.0|       NEAR BAY|\n",
            "|  -122.26|   37.84|              52.0|      696.0|         191.0|     345.0|     174.0|       2.6736|          191300.0|       NEAR BAY|\n",
            "|  -122.26|   37.85|              52.0|     2643.0|         626.0|    1212.0|     620.0|       1.9167|          159200.0|       NEAR BAY|\n",
            "|  -122.26|   37.85|              50.0|     1120.0|         283.0|     697.0|     264.0|        2.125|          140000.0|       NEAR BAY|\n",
            "|  -122.27|   37.85|              52.0|     1966.0|         347.0|     793.0|     331.0|        2.775|          152500.0|       NEAR BAY|\n",
            "|  -122.27|   37.85|              52.0|     1228.0|         293.0|     648.0|     303.0|       2.1202|          155500.0|       NEAR BAY|\n",
            "|  -122.26|   37.84|              50.0|     2239.0|         455.0|     990.0|     419.0|       1.9911|          158700.0|       NEAR BAY|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_spark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoQGO2FxmtNK"
      },
      "source": [
        "Si queremos integrar la primera fila como los nombres de las columnas hay que agregar una opción a la hora de cargar los datos en el DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37zvYB-onzJt",
        "outputId": "0c7d95a5-1db4-4088-cad3-fb4efb345c92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[longitude: string, latitude: string, housing_median_age: string, total_rooms: string, total_bedrooms: string, population: string, households: string, median_income: string, median_house_value: string, ocean_proximity: string]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#La opción option('header','true')\n",
        "df_spark_col  = spark_session.read.option('header', 'true').csv('housing.csv')\n",
        "df_spark_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w52J4vd0oIT4",
        "outputId": "042992ac-e447-45ab-f24c-eab23e49b730"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
            "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|\n",
            "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
            "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|\n",
            "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|       NEAR BAY|\n",
            "|  -122.25|   37.85|              52.0|      919.0|         213.0|     413.0|     193.0|       4.0368|          269700.0|       NEAR BAY|\n",
            "|  -122.25|   37.84|              52.0|     2535.0|         489.0|    1094.0|     514.0|       3.6591|          299200.0|       NEAR BAY|\n",
            "|  -122.25|   37.84|              52.0|     3104.0|         687.0|    1157.0|     647.0|         3.12|          241400.0|       NEAR BAY|\n",
            "|  -122.26|   37.84|              42.0|     2555.0|         665.0|    1206.0|     595.0|       2.0804|          226700.0|       NEAR BAY|\n",
            "|  -122.25|   37.84|              52.0|     3549.0|         707.0|    1551.0|     714.0|       3.6912|          261100.0|       NEAR BAY|\n",
            "|  -122.26|   37.85|              52.0|     2202.0|         434.0|     910.0|     402.0|       3.2031|          281500.0|       NEAR BAY|\n",
            "|  -122.26|   37.85|              52.0|     3503.0|         752.0|    1504.0|     734.0|       3.2705|          241800.0|       NEAR BAY|\n",
            "|  -122.26|   37.85|              52.0|     2491.0|         474.0|    1098.0|     468.0|        3.075|          213500.0|       NEAR BAY|\n",
            "|  -122.26|   37.84|              52.0|      696.0|         191.0|     345.0|     174.0|       2.6736|          191300.0|       NEAR BAY|\n",
            "|  -122.26|   37.85|              52.0|     2643.0|         626.0|    1212.0|     620.0|       1.9167|          159200.0|       NEAR BAY|\n",
            "|  -122.26|   37.85|              50.0|     1120.0|         283.0|     697.0|     264.0|        2.125|          140000.0|       NEAR BAY|\n",
            "|  -122.27|   37.85|              52.0|     1966.0|         347.0|     793.0|     331.0|        2.775|          152500.0|       NEAR BAY|\n",
            "|  -122.27|   37.85|              52.0|     1228.0|         293.0|     648.0|     303.0|       2.1202|          155500.0|       NEAR BAY|\n",
            "|  -122.26|   37.84|              50.0|     2239.0|         455.0|     990.0|     419.0|       1.9911|          158700.0|       NEAR BAY|\n",
            "|  -122.27|   37.84|              52.0|     1503.0|         298.0|     690.0|     275.0|       2.6033|          162900.0|       NEAR BAY|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_spark_col.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkGw3U3UpiD7"
      },
      "source": [
        "Como comparativa entre Pandas y PySpark ambos manejan la información dentro de DataFrames pero la función *show()* solo es aplicable en Spark mientras que *head()* funciona en ambos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBoQNiUVoSD4",
        "outputId": "83da0e28-c5b8-408f-bf38-ae848fb29043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "print(type(df_spark_col))\n",
        "print(type(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4l2FDVMqRI3"
      },
      "source": [
        "La función *head()* muestra por cada columna el valor que tiene, sin embargo muestra la información por fila utilizando este formato mencionado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2FAh9QDoha_",
        "outputId": "7846e96c-d6a4-44cb-8728-08842b864e57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(longitude='-122.23', latitude='37.88', housing_median_age='41.0', total_rooms='880.0', total_bedrooms='129.0', population='322.0', households='126.0', median_income='8.3252', median_house_value='452600.0', ocean_proximity='NEAR BAY'),\n",
              " Row(longitude='-122.22', latitude='37.86', housing_median_age='21.0', total_rooms='7099.0', total_bedrooms='1106.0', population='2401.0', households='1138.0', median_income='8.3014', median_house_value='358500.0', ocean_proximity='NEAR BAY'),\n",
              " Row(longitude='-122.24', latitude='37.85', housing_median_age='52.0', total_rooms='1467.0', total_bedrooms='190.0', population='496.0', households='177.0', median_income='7.2574', median_house_value='352100.0', ocean_proximity='NEAR BAY'),\n",
              " Row(longitude='-122.25', latitude='37.85', housing_median_age='52.0', total_rooms='1274.0', total_bedrooms='235.0', population='558.0', households='219.0', median_income='5.6431', median_house_value='341300.0', ocean_proximity='NEAR BAY'),\n",
              " Row(longitude='-122.25', latitude='37.85', housing_median_age='52.0', total_rooms='1627.0', total_bedrooms='280.0', population='565.0', households='259.0', median_income='3.8462', median_house_value='342200.0', ocean_proximity='NEAR BAY'),\n",
              " Row(longitude='-122.25', latitude='37.85', housing_median_age='52.0', total_rooms='919.0', total_bedrooms='213.0', population='413.0', households='193.0', median_income='4.0368', median_house_value='269700.0', ocean_proximity='NEAR BAY'),\n",
              " Row(longitude='-122.25', latitude='37.84', housing_median_age='52.0', total_rooms='2535.0', total_bedrooms='489.0', population='1094.0', households='514.0', median_income='3.6591', median_house_value='299200.0', ocean_proximity='NEAR BAY'),\n",
              " Row(longitude='-122.25', latitude='37.84', housing_median_age='52.0', total_rooms='3104.0', total_bedrooms='687.0', population='1157.0', households='647.0', median_income='3.12', median_house_value='241400.0', ocean_proximity='NEAR BAY'),\n",
              " Row(longitude='-122.26', latitude='37.84', housing_median_age='42.0', total_rooms='2555.0', total_bedrooms='665.0', population='1206.0', households='595.0', median_income='2.0804', median_house_value='226700.0', ocean_proximity='NEAR BAY'),\n",
              " Row(longitude='-122.25', latitude='37.84', housing_median_age='52.0', total_rooms='3549.0', total_bedrooms='707.0', population='1551.0', households='714.0', median_income='3.6912', median_house_value='261100.0', ocean_proximity='NEAR BAY')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_spark_col.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tNzS6dPrfns"
      },
      "source": [
        "Si queremos saber información acerca de los datos utilizamos la función *printSchema()* la cual muestra el nombre de cada columna, su tipo de dato y si permite valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bdNEtSRokEQ",
        "outputId": "28eb968b-1ac2-42c9-c4f2-ad939cbd2469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- longitude: string (nullable = true)\n",
            " |-- latitude: string (nullable = true)\n",
            " |-- housing_median_age: string (nullable = true)\n",
            " |-- total_rooms: string (nullable = true)\n",
            " |-- total_bedrooms: string (nullable = true)\n",
            " |-- population: string (nullable = true)\n",
            " |-- households: string (nullable = true)\n",
            " |-- median_income: string (nullable = true)\n",
            " |-- median_house_value: string (nullable = true)\n",
            " |-- ocean_proximity: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_spark_col.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-buZtUBtnOp"
      },
      "source": [
        "#Tutorial 2: Consultas en DataFrame dentro de PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "tgvc4GJCqYPD",
        "outputId": "97cd53bd-1207-4f65-98fc-c0a3dbd8c59e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/09/22 16:18:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://172.22.45.199:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_LuisTrejo1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fb5909f47c0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('OperacionesFiltrado').getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa09MN6CwPEq"
      },
      "source": [
        "Para cargar la información usaremos solamente la función *csv()* pero agregando parámetros de configuración para que tome el primer registro como los nombres de las columnas y tambien que a partir de los datos de entrada infiera el tipo de dato. Si no colocamos esto automáticamente considera de tipo *string* las columnas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n87v4tRhqpZe",
        "outputId": "45bb227d-b73e-4640-d401-f116feaad3ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           null|                 null|                 40000|\n",
            "|         null|             34|                   10|                 38000|\n",
            "|         null|             36|                 null|                  null|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark = spark.read.csv('part2.csv', header = True, inferSchema=True)\n",
        "df_filter_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4neGDBsyvX-j",
        "outputId": "6a5793f7-ea58-4371-9065-5183ab867395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Employee Name: string (nullable = true)\n",
            " |-- Age of Employee: integer (nullable = true)\n",
            " |-- Experience (in years): integer (nullable = true)\n",
            " |-- Salary (per month - $): integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWV3LXYuw0IQ"
      },
      "source": [
        "Si se necesita podemos renombrar las columnas para referirnos a ellas de una forma más sencilla o simplificada con la función *withColumnRenamed()*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr5GDyV93GOi"
      },
      "source": [
        "## Filtros y selección"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B5aqNbGrK_2",
        "outputId": "66936579-b538-4b26-a765-409dd8382f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           null|                 null|    40000|\n",
            "|         null|             34|                   10|    38000|\n",
            "|         null|             36|                 null|     null|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Salary (per month - $)\",\"EmpSalary\")\n",
        "df_filter_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUV8l1eWy90u"
      },
      "source": [
        "\n",
        "La función *filter()* nos permite filtrar la información a través de condiciones. Por ejemplo, vamos a mostrar unicamente aquellos empleados que tengan un salario menor o igual a $25,000.00."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGGtrHVxq1qB",
        "outputId": "bacd9137-15e1-43ce-bd09-1743b0fbd6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter(\"EmpSalary<=25000\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO6txvqVzdZL"
      },
      "source": [
        "Como pudieron observar hay una cierta similitud de la función *filter()* con SELECT de SQL. Es por eso que se pueden utilizar consultas SQL y tratar los DataFrames como tablas o vistas de un modelo relacional. La función *createOrReplaceTempView()* registra el DataFrame como una vista temporal dentro de la sesión que puede ejecutar consutlas SQL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSkcljBNxiKE",
        "outputId": "8c406498-d175-4c12-8b04-25aa793ac19d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           null|                 null|    40000|\n",
            "|         null|             34|                   10|    38000|\n",
            "|         null|             36|                 null|     null|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.createOrReplaceTempView(\"empleados\")\n",
        "sqlDF = spark.sql(\"SELECT * FROM empleados\")\n",
        "sqlDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4UHtcD20q8i"
      },
      "source": [
        "Si la vista temporal que se produce quieren que sea utilizada en multiples sesiones entonces hay que utilizar la función *createGlobalTempView()*. El unico detalle es que la vista quedará anclada a una base de datos llamada *global_temp*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNc4FMzG1Rln",
        "outputId": "9ed07908-03c0-4a82-d373-cf1243a91f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           null|                 null|    40000|\n",
            "|         null|             34|                   10|    38000|\n",
            "|         null|             36|                 null|     null|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.createGlobalTempView(\"g_empleados\")\n",
        "sqlDF = spark.sql(\"SELECT * FROM global_temp.g_empleados\")\n",
        "sqlDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ATcN_3S1162"
      },
      "source": [
        "Como mencionamos la vista perdura en otras sesiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR9qBGWh1-rz",
        "outputId": "3712d2bf-014a-40af-9657-323189494645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           null|                 null|    40000|\n",
            "|         null|             34|                   10|    38000|\n",
            "|         null|             36|                 null|     null|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.newSession().sql(\"SELECT * FROM global_temp.g_empleados\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOw7X7R92H1a"
      },
      "source": [
        "Se puede de igual forma cambiar el nombre de multiples columnas al mismo tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vkSgApfrlzG",
        "outputId": "ebb6f1f4-80a5-4a7c-bcec-71c4b983d477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+---------------------+---------+\n",
            "|EmpName|EmpAge|Experience (in years)|EmpSalary|\n",
            "+-------+------+---------------------+---------+\n",
            "| Oliver|    31|                   10|    30000|\n",
            "|  Harry|    30|                    8|    25000|\n",
            "| George|    29|                    4|    20000|\n",
            "|   Jack|    24|                    3|    20000|\n",
            "|  Jacob|    21|                    1|    15000|\n",
            "|    Leo|    23|                    2|    18000|\n",
            "|  Oscar|  null|                 null|    40000|\n",
            "|   null|    34|                   10|    38000|\n",
            "|   null|    36|                 null|     null|\n",
            "+-------+------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Cambiamos el nombre de multiples columnas\n",
        "df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Age of Employee\",\"EmpAge\").withColumnRenamed(\"Employee Name\",\"EmpName\")\n",
        "df_filter_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73Rl2uG32Q_Z"
      },
      "source": [
        "Al igual que en SQL se pueden seleccionar las columnas que serán mostradas dentro de la consulta acompañando a la función *filter()* con la función *select()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGtFqXeyri3Z",
        "outputId": "e38ac823-5a0c-4f0b-a057-e03760df3789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|EmpName|EmpAge|\n",
            "+-------+------+\n",
            "|  Harry|    30|\n",
            "| George|    29|\n",
            "|   Jack|    24|\n",
            "|  Jacob|    21|\n",
            "|    Leo|    23|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter(\"EmpSalary<=25000\").select(['EmpName','EmpAge']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXx1CwoD2sW1"
      },
      "source": [
        "Otra manera de filtrar la información de los registros es utilizar un estilo similar a Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOZuURvRr4HZ",
        "outputId": "0c35ce46-b4e3-451c-8432-00ce6b694ed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|EmpName|EmpAge|\n",
            "+-------+------+\n",
            "|  Harry|    30|\n",
            "| George|    29|\n",
            "|   Jack|    24|\n",
            "|  Jacob|    21|\n",
            "|    Leo|    23|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter(df_filter_pyspark['EmpSalary']<=25000).select(['EmpName','EmpAge']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlPM5Da224mk"
      },
      "source": [
        "## Operadores Lógicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHT4extP4NfO"
      },
      "source": [
        "Los operadores lógicos disponibles son AND (&), OR (|) y NOT (~)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOTdAcq64fFd"
      },
      "source": [
        "Ejemplo con AND: Los empleados que su salario sea menor o igual a \\$30,000.00 y que sea mayor o igual a \\$18,000.00."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYgWyHBUsDw-",
        "outputId": "99d4e659-5541-4eac-c40b-b4a3e1b78ffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+---------------------+---------+\n",
            "|EmpName|EmpAge|Experience (in years)|EmpSalary|\n",
            "+-------+------+---------------------+---------+\n",
            "| Oliver|    31|                   10|    30000|\n",
            "|  Harry|    30|                    8|    25000|\n",
            "| George|    29|                    4|    20000|\n",
            "|   Jack|    24|                    3|    20000|\n",
            "|    Leo|    23|                    2|    18000|\n",
            "+-------+------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter((df_filter_pyspark['EmpSalary']<=30000)\n",
        "                          & (df_filter_pyspark['EmpSalary']>=18000)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjuqaJ80syOs",
        "outputId": "f12aabb3-08c6-4e60-8b82-ed9dfcad3a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+-------------+---------+\n",
            "|EmpName|EmpAge|EmpExperience|EmpSalary|\n",
            "+-------+------+-------------+---------+\n",
            "| Oliver|    31|           10|    30000|\n",
            "|  Harry|    30|            8|    25000|\n",
            "| George|    29|            4|    20000|\n",
            "|   Jack|    24|            3|    20000|\n",
            "|  Jacob|    21|            1|    15000|\n",
            "|    Leo|    23|            2|    18000|\n",
            "|  Oscar|  null|         null|    40000|\n",
            "|   null|    34|           10|    38000|\n",
            "|   null|    36|         null|     null|\n",
            "+-------+------+-------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Cambiamos el nombre de la columna experiencia\n",
        "df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Experience (in years)\",\"EmpExperience\")\n",
        "df_filter_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "latXscc144pR"
      },
      "source": [
        "Ejemplo con OR: Los empleados que su salario sea menor o igual a \\$30,000.00 ó que su experiencia laboral sea mayor o igual a 3 años."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxIIaEmvsvvA",
        "outputId": "f55d8c27-c30a-49d1-bc75-b60014b0e3cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+-------------+---------+\n",
            "|EmpName|EmpAge|EmpExperience|EmpSalary|\n",
            "+-------+------+-------------+---------+\n",
            "| Oliver|    31|           10|    30000|\n",
            "|  Harry|    30|            8|    25000|\n",
            "| George|    29|            4|    20000|\n",
            "|   Jack|    24|            3|    20000|\n",
            "|  Jacob|    21|            1|    15000|\n",
            "|    Leo|    23|            2|    18000|\n",
            "|   null|    34|           10|    38000|\n",
            "+-------+------+-------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter((df_filter_pyspark['EmpSalary']<=30000)\n",
        "                          | (df_filter_pyspark['EmpExperience']>=3)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFxPQ4OL5YIR"
      },
      "source": [
        "Ejemplo NOT: Los empleandos que su edad no sea mayor o igual a 30 años."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohEM94QPs9UE",
        "outputId": "834be1ba-7770-4b9c-9533-9ba11ff1decd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+-------------+---------+\n",
            "|EmpName|EmpAge|EmpExperience|EmpSalary|\n",
            "+-------+------+-------------+---------+\n",
            "| George|    29|            4|    20000|\n",
            "|   Jack|    24|            3|    20000|\n",
            "|  Jacob|    21|            1|    15000|\n",
            "|    Leo|    23|            2|    18000|\n",
            "+-------+------+-------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter(~(df_filter_pyspark['EmpAge']>=30)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikvKjBuY6e7-"
      },
      "source": [
        "# Tutorial 3: Manejo de valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "2WFOahsM6utd",
        "outputId": "44c281f5-9ccc-49b9-bc27-1be3860f6b7e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://1040695525b7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_LuisTrejo1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x782ed5c729b0>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Creamos una sesión de PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "null_spark = SparkSession.builder.appName('ValoresNulos').getOrCreate()\n",
        "null_spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5TJdLAp7ASc",
        "outputId": "5f93aa81-be76-4328-8624-4ffc48be3d44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[Employee Name: string, Age of Employee: int, Experience (in years): int, Salary (per month - $): int]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Cargamos los datos dentro de un DataFrame de la sesión\n",
        "df_null_pyspark = null_spark.read.csv('part2.csv', header = True, inferSchema = True)\n",
        "df_null_pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NXstlu57QSQ",
        "outputId": "968f38ce-2fee-4cb9-e369-d9e806cabd66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|\n",
            "|         NULL|             34|                   10|                 38000|\n",
            "|         NULL|             36|                 NULL|                  NULL|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Visualizamos la información\n",
        "df_null_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAflsQi47elO",
        "outputId": "fb3b7fb5-90df-4d7d-b32b-f8a168dbfdaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Employee Name: string (nullable = true)\n",
            " |-- Age of Employee: integer (nullable = true)\n",
            " |-- Experience (in years): integer (nullable = true)\n",
            " |-- Salary (per month - $): integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Nuevamente vemos la estructura de la información\n",
        "# recordando que cuando tenemos nullable = true significa que esa columna permite\n",
        "# valores nulos\n",
        "df_null_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPVY4QKT728z"
      },
      "source": [
        "La función para eliminar los valores nulos dentro de la información es *na.drop()*. Esta función elimina completamente los registros que tiene algún valor nulo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk7qANkD72Z4",
        "outputId": "595500bd-7baf-4af2-e846-242e81539e1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.drop().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HULRD2Mr8WUI"
      },
      "source": [
        "Si queremos controlar el como se eliminan los registros la función tiene un parámetro llamado *how* con dos posibles valores:\n",
        "\n",
        "\n",
        "*   ALL: Elimina la tupla siempre y cuando todos los valores asociados a cada columna sean nulos.\n",
        "*   ANY: Elimina la tupla si alguno de los valores asociados a cada columns es nulo. Esta es la configuración por default.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI5INUDi9DCE",
        "outputId": "7692bb3c-1d14-469b-9e7f-ada92d750fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|\n",
            "|         NULL|             34|                   10|                 38000|\n",
            "|         NULL|             36|                 NULL|                  NULL|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.drop(how=\"all\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7EqNcvQ9G02",
        "outputId": "8531d46d-55ad-43c2-ea6a-a0b5cee8b662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.drop(how=\"any\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-m7EXqo9L8f"
      },
      "source": [
        "Tambien hay forma de especificar el número mínimo de valores nulos aceptables con el parámetro *thresh*. En el ejemplo se puede observar que elimina solo una tupla que tenia tres valores nulos asociados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEZfXpS49XDo",
        "outputId": "e3ed2421-45f8-43da-b710-191d3e33ffe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|\n",
            "|         NULL|             34|                   10|                 38000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.drop(thresh=2).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKMI4Qmc9yji"
      },
      "source": [
        "De igual forma podemos cambiar el parámetro *how* con *subset* para indicarle las columnas donde nos interesan detectar valores nulos en las tuplas y eliminarlas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhma9LrN9ya0",
        "outputId": "595a1552-83f1-49e0-8b50-039c5a9e05dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|         NULL|             34|                   10|                 38000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.drop(how='any', subset=['Experience (in years)']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKkz--0i-Oyk"
      },
      "source": [
        "Podemos rellenar los valores nulos con algún valor en especifico utilizando la función *na.fill()* indicando el valor y la columna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAMqYGjo-krE",
        "outputId": "66805c68-fe92-4fca-bd6f-58b6a3301c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|\n",
            "| LT NA values|             34|                   10|                 38000|\n",
            "| LT NA values|             36|                 NULL|                  NULL|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.fill('LT NA values', 'Employee Name').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbXa3gu6-u4i"
      },
      "source": [
        "Otra alternativa para rellenar los valores faltantes es utilizando el método de imputación de datos utilizando la media. Para esto hay que utilizar la clase *Imputer* especificando las columnas de entrada y las de salida que se agregaran al DataFrame así como la estrategia en este caso utilizar la media. Después, se utiliza la función *fit()* y *transform()* para integrar las columnas imputadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FAlh9Sy-vBv",
        "outputId": "6d9fc0e0-87ad-402d-89aa-0ca87060247e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|Age of Employee_imputed|Experience (in years)_imputed|Salary (per month - $)_imputed|\n",
            "+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n",
            "|       Oliver|             31|                   10|                 30000|                     31|                           10|                         30000|\n",
            "|        Harry|             30|                    8|                 25000|                     30|                            8|                         25000|\n",
            "|       George|             29|                    4|                 20000|                     29|                            4|                         20000|\n",
            "|         Jack|             24|                    3|                 20000|                     24|                            3|                         20000|\n",
            "|        Jacob|             21|                    1|                 15000|                     21|                            1|                         15000|\n",
            "|          Leo|             23|                    2|                 18000|                     23|                            2|                         18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|                     28|                            5|                         40000|\n",
            "|         NULL|             34|                   10|                 38000|                     34|                           10|                         38000|\n",
            "|         NULL|             36|                 NULL|                  NULL|                     36|                            5|                         25750|\n",
            "+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)'],\n",
        "    outputCols = [\"{}_imputed\".format(a) for a in ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)']]\n",
        ").setStrategy(\"mean\")\n",
        "imputer.fit(df_null_pyspark).transform(df_null_pyspark).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_zMjiAbClef"
      },
      "source": [
        "# Tutorial 4: Manejo de DataFrames en PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "gWBdsz42Czua",
        "outputId": "a79036ef-4239-46b1-e5ba-04565b6e4387"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0bd152a0a3aa:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_LuisTrejo1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f55143782d0>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Creamos la sesión de trabajo\n",
        "from pyspark.sql import SparkSession\n",
        "data_spark = SparkSession.builder.appName('DataFrame_article').getOrCreate()\n",
        "data_spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I1c0TjrC9Sv",
        "outputId": "73de5e6f-8e17-4357-a1db-7da12fd539e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Cargamos los datos e imprimimos la descripción del schema\n",
        "df_pyspark = data_spark.read.option('header','true').csv('/content/sample_data/california_housing_train.csv', inferSchema=True)\n",
        "df_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5q5LqAcMVM3",
        "outputId": "838303d7-9aaf-493d-988a-d96d69907d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n",
            "|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n",
            "|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n",
            "|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n",
            "|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n",
            "|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n",
            "|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Visualizamos la información\n",
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSz7YI4wMscN"
      },
      "source": [
        "En caso de querer cambiar el tipo de dato de alguna columna lo podemos hacer con las funciones *withColumn()* y *cast()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWt7j0x4MslB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import column\n",
        "df_pyspark=df_pyspark.withColumn(\"housing_median_age\",column(\"housing_median_age\").cast(\"int\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Oubrma8MEU-"
      },
      "source": [
        "Con el atributo *dtypes* podemos saber el tipo de dato por columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QJEKDVHDHrE",
        "outputId": "ad7ec212-f7e1-4cf5-8ffb-a8ab438a39c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('longitude', 'double'),\n",
              " ('latitude', 'double'),\n",
              " ('housing_median_age', 'int'),\n",
              " ('total_rooms', 'double'),\n",
              " ('total_bedrooms', 'double'),\n",
              " ('population', 'double'),\n",
              " ('households', 'double'),\n",
              " ('median_income', 'double'),\n",
              " ('median_house_value', 'double')]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pyspark.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghry7pbYN43p"
      },
      "source": [
        "Si queremos saber el nombre de las columnas utilizamos el atributo *columns*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RjGvsq_DT4k",
        "outputId": "8cd49476-b581-4c51-80cf-51f2a48793f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['longitude',\n",
              " 'latitude',\n",
              " 'housing_median_age',\n",
              " 'total_rooms',\n",
              " 'total_bedrooms',\n",
              " 'population',\n",
              " 'households',\n",
              " 'median_income',\n",
              " 'median_house_value']"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pyspark.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdcYuuXAOBr3"
      },
      "source": [
        "También, se puede seleccionar todos los datos de una columna en particular con la función *select()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k3Qp6F9DWVP",
        "outputId": "701dd4f6-9f3d-439a-db8f-a801df3efa26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|total_rooms|\n",
            "+-----------+\n",
            "|     5612.0|\n",
            "|     7650.0|\n",
            "|      720.0|\n",
            "|     1501.0|\n",
            "|     1454.0|\n",
            "|     1387.0|\n",
            "|     2907.0|\n",
            "|      812.0|\n",
            "|     4789.0|\n",
            "|     1497.0|\n",
            "|     3741.0|\n",
            "|     1988.0|\n",
            "|     1291.0|\n",
            "|     2478.0|\n",
            "|     1448.0|\n",
            "|     2556.0|\n",
            "|     1678.0|\n",
            "|       44.0|\n",
            "|     1388.0|\n",
            "|       97.0|\n",
            "+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.select('total_rooms').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5T8sf9yOUxs"
      },
      "source": [
        "O en caso de querer seleccionar varias columnas tambien se puede lograr enviando una lista con el nombre de las columnas como parámetro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JpH1i60DZVk",
        "outputId": "10b6022e-955a-49f3-8d30-5390dc62473e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------------+-------------+\n",
            "|total_rooms|total_bedrooms|median_income|\n",
            "+-----------+--------------+-------------+\n",
            "|     5612.0|        1283.0|       1.4936|\n",
            "|     7650.0|        1901.0|         1.82|\n",
            "|      720.0|         174.0|       1.6509|\n",
            "|     1501.0|         337.0|       3.1917|\n",
            "|     1454.0|         326.0|        1.925|\n",
            "|     1387.0|         236.0|       3.3438|\n",
            "|     2907.0|         680.0|       2.6768|\n",
            "|      812.0|         168.0|       1.7083|\n",
            "|     4789.0|        1175.0|       2.1782|\n",
            "|     1497.0|         309.0|       2.1908|\n",
            "|     3741.0|         801.0|       2.6797|\n",
            "|     1988.0|         483.0|        1.625|\n",
            "|     1291.0|         248.0|       2.1571|\n",
            "|     2478.0|         464.0|        3.212|\n",
            "|     1448.0|         378.0|       0.8585|\n",
            "|     2556.0|         587.0|       1.6991|\n",
            "|     1678.0|         322.0|       2.9653|\n",
            "|       44.0|          33.0|       0.8571|\n",
            "|     1388.0|         386.0|       1.2049|\n",
            "|       97.0|          24.0|       1.2656|\n",
            "+-----------+--------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.select(['total_rooms', 'total_bedrooms', 'median_income']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3KgSo5MOg6f"
      },
      "source": [
        "Si queremos saber algunas medidas de tendencia central de los datos para los análisis estadísticos se puede utilizar la función *describe()* similar a Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfKnLrhzDbua",
        "outputId": "dca4ac95-4fcf-49a2-fccb-600bed8e2eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|summary|          longitude|          latitude|housing_median_age|      total_rooms|   total_bedrooms|        population|       households|     median_income|median_house_value|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|  count|              17000|             17000|             17000|            17000|            17000|             17000|            17000|             17000|             17000|\n",
            "|   mean|-119.56210823529375|  35.6252247058827| 28.58935294117647|2643.664411764706|539.4108235294118|1429.5739411764705|501.2219411764706| 3.883578100000021|207300.91235294117|\n",
            "| stddev| 2.0051664084260357|2.1373397946570867|12.586936981660406|2179.947071452777|421.4994515798648| 1147.852959159527|384.5208408559016|1.9081565183791036|115983.76438720895|\n",
            "|    min|            -124.35|             32.54|                 1|              2.0|              1.0|               3.0|              1.0|            0.4999|           14999.0|\n",
            "|    max|            -114.31|             41.95|                52|          37937.0|           6445.0|           35682.0|           6082.0|           15.0001|          500001.0|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE5gL9snPdsE"
      },
      "source": [
        "De igual manera se pueden agregar columnas directamente al DataFrame si se requiere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t38O8t0cDfY3",
        "outputId": "d6c0a1e3-d969-4f84-e9de-efd058cfa44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|Updated_medianhousevalue|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n",
            "|  -114.31|   34.19|                15|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|                133800.0|\n",
            "|  -114.47|    34.4|                19|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|                160200.0|\n",
            "|  -114.56|   33.69|                17|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|                171400.0|\n",
            "|  -114.57|   33.64|                14|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|                146800.0|\n",
            "|  -114.57|   33.57|                20|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|                131000.0|\n",
            "|  -114.58|   33.63|                29|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|                148000.0|\n",
            "|  -114.58|   33.61|                25|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|                164800.0|\n",
            "|  -114.59|   34.83|                41|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|                 97000.0|\n",
            "|  -114.59|   33.61|                34|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|                116800.0|\n",
            "|   -114.6|   34.83|                46|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|                 96200.0|\n",
            "|   -114.6|   33.62|                16|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|                173000.0|\n",
            "|   -114.6|    33.6|                21|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|                124000.0|\n",
            "|  -114.61|   34.84|                48|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|                 97200.0|\n",
            "|  -114.61|   34.83|                31|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|                140800.0|\n",
            "|  -114.63|   32.76|                15|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|                 90000.0|\n",
            "|  -114.65|   34.89|                17|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|                138200.0|\n",
            "|  -114.65|    33.6|                28|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|                189800.0|\n",
            "|  -114.65|   32.79|                21|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|                 50000.0|\n",
            "|  -114.66|   32.74|                17|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|                 88000.0|\n",
            "|  -114.67|   33.92|                17|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|                 55000.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark = df_pyspark.withColumn('Updated_medianhousevalue', df_pyspark['median_house_value']*2)\n",
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHB46MbDPnmZ"
      },
      "source": [
        "De igual forma se pueden eliminar con la función *drop()*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5Vp00etD_LX",
        "outputId": "67310cd7-85c9-41c7-d9da-04adbd489016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|                15|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|                19|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|                17|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|                14|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|                20|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|                29|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|                25|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|                41|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|                34|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|                46|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|   -114.6|   33.62|                16|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n",
            "|   -114.6|    33.6|                21|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n",
            "|  -114.61|   34.84|                48|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.61|   34.83|                31|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n",
            "|  -114.63|   32.76|                15|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.65|   34.89|                17|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n",
            "|  -114.65|    33.6|                28|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n",
            "|  -114.65|   32.79|                21|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n",
            "|  -114.66|   32.74|                17|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.67|   33.92|                17|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.drop('Updated_medianhousevalue').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYc2mWGlPxFH"
      },
      "source": [
        "# Tutorial 5: Agregación y agrupamientos\n",
        "\n",
        "Agrupar los datos es una de las habilidades más esenciales cuando trabajamos con Big Data dado que estamos tratando con una gran cantidad de datos y si no somos capaces de segmentar esos datos, entonces será mucho más difícil analizarlos y usarlos para obtener información relevante\n",
        "\n",
        "La regla de oro es recordar que la función *groupBy()* y la función de agregación van de la mano, es decir, no podemos usar groupBy sin la función agregada como SUM, COUNT, AVG, MAX, MIN, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "pCMVYeyoT0dq",
        "outputId": "e94d4fe5-c6d8-47b9-87fa-9638da1eb058"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0bd152a0a3aa:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_LuisTrejo1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f55143782d0>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark_aggregate = SparkSession.builder.appName('Aggregate and GroupBy').getOrCreate()\n",
        "spark_aggregate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8YpcNuaTtUQ",
        "outputId": "7db2ec75-607d-4b26-dcd3-cbb934ccc6b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------+------+\n",
            "|  Name|  Departmens|salary|\n",
            "+------+------------+------+\n",
            "|Oliver|Data Science| 10000|\n",
            "|Oliver|         IOT|  5000|\n",
            "| Johny|    Big Data|  4000|\n",
            "|Oliver|    Big Data|  4000|\n",
            "| Johny|Data Science|  3000|\n",
            "|Mathew|Data Science| 20000|\n",
            "|Mathew|         IOT| 10000|\n",
            "|Mathew|    Big Data|  5000|\n",
            "| Jacob|Data Science| 10000|\n",
            "| Jacob|    Big Data|  2000|\n",
            "+------+------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data = spark_aggregate.read.csv('part4.csv', header = True, inferSchema = True)\n",
        "spark_aggregate_data.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j74wnJlET8Gk"
      },
      "source": [
        "Si llegamos a ejecutar unicamente la función *groupBy()* la respuesta será la ubicación de los datos agrupados lo cual no es relevante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9mnirSyS6O5",
        "outputId": "ff494b25-4b69-44ea-dc4b-c2cef27d10b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyspark.sql.group.GroupedData at 0x7f5510f6a290>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Name')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAlB-sLiUZGS"
      },
      "source": [
        "## Funciones de agregación\n",
        "\n",
        "Algunas de las funciones más comunes son:\n",
        "\n",
        "\n",
        "\n",
        "*   AVG: devuelve el conjunto de resultados agrupando la columna según el promedio del conjunto de valores.\n",
        "*   COUNT: devolverá el número total de conjuntos de valores en una columna particular correspondiente a la función groupBy.\n",
        "*   MIN: devuelve el valor mínimo o más pequeño entre todo el conjunto de valores en toda la fila.\n",
        "*   MAX: el funcionamiento y el enfoque de usar la función agregada MAX es el mismo que la función agregada MIN, solo que la principal diferencia es que devolverá el valor máximo entre el conjunto de valores en la fila.\n",
        "*   SUM: devolverá la suma de todos los valores numéricos correspondientes a la columna agrupada\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGaco-YtWYNH"
      },
      "source": [
        "Si ejecutamos la función de agrupamiento y agregación el resultado será la descripción del DataFrame por lo que si queremos visualizar la información hay que utilizar la función *show()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-35ZH9tVBHq",
        "outputId": "0e69f727-90d9-4ed0-fa96-031817ef1aa6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[Name: string, sum(salary): bigint]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Name').sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q54ThS92XAqX"
      },
      "source": [
        "Ejemplo: Conocer la cantidad de dinero total que le pago la compañia a cada empleado agrupando por nombre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHDQqxfGW0PD",
        "outputId": "5a5662bb-72e4-48b2-b383-f7817c2ccfee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----------+\n",
            "|  Name|sum(salary)|\n",
            "+------+-----------+\n",
            "| Jacob|      12000|\n",
            "| Johny|       7000|\n",
            "|Mathew|      35000|\n",
            "|Oliver|      19000|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Name').sum().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyyW7WWZXHx4"
      },
      "source": [
        "Ejemplo: Conocer la cantidad de dinero total que pago cada departamento a sus empleados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5st2YW3XPIS",
        "outputId": "ba9914d9-295f-445c-fd19-c15c09231e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-----------+\n",
            "|  Departmens|sum(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      15000|\n",
            "|    Big Data|      15000|\n",
            "|Data Science|      43000|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Departmens').sum().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3imE2OXvXaIx"
      },
      "source": [
        "Ejemplo: Conocer el salario promedio que se le pago a los empleados por departamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdtCu_hsXnO5",
        "outputId": "1e4c7111-b539-4b26-99a3-38ce1b688e86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-----------+\n",
            "|  Departmens|avg(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|     7500.0|\n",
            "|    Big Data|     3750.0|\n",
            "|Data Science|    10750.0|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Departmens').mean().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlhwGhpkXylB"
      },
      "source": [
        "Ejemplo: Saber el número de pagos que recibio cada empleado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEowM03EXywJ",
        "outputId": "3a7169d3-5f61-46e2-c844-cbcad7fcdb51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|  Name|count|\n",
            "+------+-----+\n",
            "| Jacob|    2|\n",
            "| Johny|    2|\n",
            "|Mathew|    3|\n",
            "|Oliver|    3|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy(['Name']).count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9pddSi7WG57",
        "outputId": "fe99ab6f-df0f-43a5-eb2e-6306bc96a9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|  Name|count|\n",
            "+------+-----+\n",
            "| Jacob|    2|\n",
            "| Johny|    2|\n",
            "|Mathew|    3|\n",
            "|Oliver|    3|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Name').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp8fPy5Ot-vk"
      },
      "source": [
        "Extracción de valores numércios\n",
        "Referencia\n",
        "https://www.geeksforgeeks.org/get-value-of-a-particular-cell-in-pyspark-dataframe/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45Te74Cxt9n_",
        "outputId": "bf900295-7408-4d14-a420-a3c614d7e3e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------+------+\n",
            "|  Name|  Departmens|salary|\n",
            "+------+------------+------+\n",
            "|Oliver|Data Science| 10000|\n",
            "|Oliver|         IOT|  5000|\n",
            "| Johny|    Big Data|  4000|\n",
            "|Oliver|    Big Data|  4000|\n",
            "| Johny|Data Science|  3000|\n",
            "|Mathew|Data Science| 20000|\n",
            "|Mathew|         IOT| 10000|\n",
            "|Mathew|    Big Data|  5000|\n",
            "| Jacob|Data Science| 10000|\n",
            "| Jacob|    Big Data|  2000|\n",
            "+------+------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDC1E2qSvAgd"
      },
      "source": [
        "Extraer el primer renglón"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1QCsdBXvFu8",
        "outputId": "884e5ed6-c0cc-4c8e-c58f-89c08b66dfb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Row(Name='Oliver', Departmens='Data Science', salary=10000)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark_aggregate_data.collect()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3eryxy-vI2F"
      },
      "source": [
        "Extarer su Salario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcO3w6PMvLfE",
        "outputId": "09c5649a-2359-4ec1-8cab-9ae446a5c7d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15000.0"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Salario = spark_aggregate_data.collect()[0][2]\n",
        "Salario\n",
        "Salario = Salario * 1.5\n",
        "Salario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHhiL2rneKF5"
      },
      "source": [
        "# Tutorial 6: Usando ML en PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "lzkltL3aeXm-",
        "outputId": "e334c41b-dafd-4852-fb9b-64db5bbb5d83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://60ace41a9e26:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>EjemploML</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f6a7ca40310>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "df_ml = SparkSession.builder.appName('EjemploML').getOrCreate()\n",
        "df_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tumrUfnSf8z4",
        "outputId": "cf70a46d-b714-4f46-d297-073179f56709"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[age: int, selling_price: int, km_driven: int, mileage: double, engine: int, max_power: double, seats: int]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Cargamos la información en un DataFrame\n",
        "training_dataset  = df_ml.read.csv('UserCarDataExample.csv', header=True, inferSchema=True)\n",
        "training_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb1J2b66gLEE",
        "outputId": "7ca9d1ab-0047-40da-830d-eb0125081634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------------+---------+-------+------+---------+-----+\n",
            "|age|selling_price|km_driven|mileage|engine|max_power|seats|\n",
            "+---+-------------+---------+-------+------+---------+-----+\n",
            "|  8|       450000|   145500|   23.4|  1248|     74.0|    5|\n",
            "|  8|       370000|   120000|  21.14|  1498|   103.52|    5|\n",
            "| 16|       158000|   140000|   17.7|  1497|     78.0|    5|\n",
            "| 12|       225000|   127000|   23.0|  1396|     90.0|    5|\n",
            "| 15|       130000|   120000|   16.1|  1298|     88.2|    5|\n",
            "|  5|       440000|    45000|  20.14|  1197|    81.86|    5|\n",
            "| 15|        96000|   175000|   17.3|  1061|     57.5|    5|\n",
            "| 21|        45000|     5000|   16.1|   796|     37.0|    4|\n",
            "| 11|       350000|    90000|  23.59|  1364|     67.1|    5|\n",
            "|  9|       200000|   169000|   20.0|  1399|     68.1|    5|\n",
            "|  8|       500000|    68000|  19.01|  1461|   108.45|    5|\n",
            "| 17|        92000|   100000|   17.3|   993|     60.0|    5|\n",
            "| 13|       280000|   140000|   19.3|  1248|     73.9|    5|\n",
            "| 13|       180000|    90000|   18.9|  1061|     67.0|    5|\n",
            "|  6|       400000|    40000|  18.15|  1198|     82.0|    5|\n",
            "|  6|       778000|    70000|  24.52|  1248|     88.5|    7|\n",
            "| 10|       500000|    53000|   23.0|  1396|     90.0|    5|\n",
            "| 20|       150000|    80000|   19.7|   796|     46.3|    5|\n",
            "|  6|       680000|   100000|  22.54|  1396|    88.73|    5|\n",
            "| 11|       174000|   100000|   21.0|  1461|     64.1|    5|\n",
            "+---+-------------+---------+-------+------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Mostramos la información\n",
        "training_dataset.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H4E0wYKgOnS",
        "outputId": "d0fdbf5f-ba5d-43e8-af49-f4a6d1896fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- selling_price: integer (nullable = true)\n",
            " |-- km_driven: integer (nullable = true)\n",
            " |-- mileage: double (nullable = true)\n",
            " |-- engine: integer (nullable = true)\n",
            " |-- max_power: double (nullable = true)\n",
            " |-- seats: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Visualizamos el esquema de la base de datos\n",
        "training_dataset.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQkaCFvAgRL2",
        "outputId": "84bce780-5d01-4715-b140-bc1a7a24c684"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['age',\n",
              " 'selling_price',\n",
              " 'km_driven',\n",
              " 'mileage',\n",
              " 'engine',\n",
              " 'max_power',\n",
              " 'seats']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Visualizamos el nombre de las columnas\n",
        "training_dataset.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moU5VyLK8tlJ"
      },
      "source": [
        "Para trabajar con modelos de regresión tenemos que utilizar *VectorAssembler* para convertir las variables independientes en un vector que las incluya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw-DruM-gkRm",
        "outputId": "e893910e-0111-4c02-d7a6-900ceb4d753e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorAssembler_bf6225cdeb5d"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "featassembler = VectorAssembler(inputCols=['age',\n",
        " 'km_driven',\n",
        " 'mileage',\n",
        " 'engine',\n",
        " 'max_power',\n",
        " 'seats'], outputCol = \"Independent Features\" )\n",
        "featassembler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j2BdYSb9LCY"
      },
      "source": [
        "Posteriormente se integran al conjunto de datos que ya estaba cargado utilizando la función *transform()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSF0ijSFgsqS",
        "outputId": "ab797cfb-2ed7-4be8-a423-c8e609c3cb3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------------+---------+-------+------+---------+-----+--------------------+\n",
            "|age|selling_price|km_driven|mileage|engine|max_power|seats|Independent Features|\n",
            "+---+-------------+---------+-------+------+---------+-----+--------------------+\n",
            "|  8|       450000|   145500|   23.4|  1248|     74.0|    5|[8.0,145500.0,23....|\n",
            "|  8|       370000|   120000|  21.14|  1498|   103.52|    5|[8.0,120000.0,21....|\n",
            "| 16|       158000|   140000|   17.7|  1497|     78.0|    5|[16.0,140000.0,17...|\n",
            "| 12|       225000|   127000|   23.0|  1396|     90.0|    5|[12.0,127000.0,23...|\n",
            "| 15|       130000|   120000|   16.1|  1298|     88.2|    5|[15.0,120000.0,16...|\n",
            "|  5|       440000|    45000|  20.14|  1197|    81.86|    5|[5.0,45000.0,20.1...|\n",
            "| 15|        96000|   175000|   17.3|  1061|     57.5|    5|[15.0,175000.0,17...|\n",
            "| 21|        45000|     5000|   16.1|   796|     37.0|    4|[21.0,5000.0,16.1...|\n",
            "| 11|       350000|    90000|  23.59|  1364|     67.1|    5|[11.0,90000.0,23....|\n",
            "|  9|       200000|   169000|   20.0|  1399|     68.1|    5|[9.0,169000.0,20....|\n",
            "|  8|       500000|    68000|  19.01|  1461|   108.45|    5|[8.0,68000.0,19.0...|\n",
            "| 17|        92000|   100000|   17.3|   993|     60.0|    5|[17.0,100000.0,17...|\n",
            "| 13|       280000|   140000|   19.3|  1248|     73.9|    5|[13.0,140000.0,19...|\n",
            "| 13|       180000|    90000|   18.9|  1061|     67.0|    5|[13.0,90000.0,18....|\n",
            "|  6|       400000|    40000|  18.15|  1198|     82.0|    5|[6.0,40000.0,18.1...|\n",
            "|  6|       778000|    70000|  24.52|  1248|     88.5|    7|[6.0,70000.0,24.5...|\n",
            "| 10|       500000|    53000|   23.0|  1396|     90.0|    5|[10.0,53000.0,23....|\n",
            "| 20|       150000|    80000|   19.7|   796|     46.3|    5|[20.0,80000.0,19....|\n",
            "|  6|       680000|   100000|  22.54|  1396|    88.73|    5|[6.0,100000.0,22....|\n",
            "| 11|       174000|   100000|   21.0|  1461|     64.1|    5|[11.0,100000.0,21...|\n",
            "+---+-------------+---------+-------+------+---------+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = featassembler.transform(training_dataset)\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEIplNaj9aTy"
      },
      "source": [
        "Para construir nuestro modelo de regresión debemos selecccionar la columna que integró los valores de las columnas en un vector y la columna que representa la variable dependiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkN24b3_gxBD",
        "outputId": "1e14e299-5bec-483d-b474-1d75531aa47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+\n",
            "|Independent features|selling_price|\n",
            "+--------------------+-------------+\n",
            "|[8.0,145500.0,23....|       450000|\n",
            "|[8.0,120000.0,21....|       370000|\n",
            "|[16.0,140000.0,17...|       158000|\n",
            "|[12.0,127000.0,23...|       225000|\n",
            "|[15.0,120000.0,16...|       130000|\n",
            "|[5.0,45000.0,20.1...|       440000|\n",
            "|[15.0,175000.0,17...|        96000|\n",
            "|[21.0,5000.0,16.1...|        45000|\n",
            "|[11.0,90000.0,23....|       350000|\n",
            "|[9.0,169000.0,20....|       200000|\n",
            "|[8.0,68000.0,19.0...|       500000|\n",
            "|[17.0,100000.0,17...|        92000|\n",
            "|[13.0,140000.0,19...|       280000|\n",
            "|[13.0,90000.0,18....|       180000|\n",
            "|[6.0,40000.0,18.1...|       400000|\n",
            "|[6.0,70000.0,24.5...|       778000|\n",
            "|[10.0,53000.0,23....|       500000|\n",
            "|[20.0,80000.0,19....|       150000|\n",
            "|[6.0,100000.0,22....|       680000|\n",
            "|[11.0,100000.0,21...|       174000|\n",
            "+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "final_data = result.select(\"Independent features\", \"selling_price\")\n",
        "final_data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXw3mdLr-ieZ"
      },
      "source": [
        "Del conjunto total de datos se puede generar un división de conjunto de datos entre entrenamiento y prueba con la función *randomSplit*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRqfuLCSg3WF"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = final_data.randomSplit([0.75, 0.25])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1enV5l9G-ul7"
      },
      "source": [
        "Ahora bien hay que importar *LinearRegression* de la biblioteca de machine learning de PySpark. Especificando cuales son la variables independientes y cual es la dependiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzyfNi_5g6Ro"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "model = LinearRegression(featuresCol = 'Independent features', labelCol='selling_price')\n",
        "model = model.fit(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWZ7qUpPANhH"
      },
      "source": [
        "Podemos imprimir la matriz de correlación para verificar la congruencia del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_PZNczQjDUy",
        "outputId": "5dd85152-0244-410d-8a19-77e376d82703"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/spark-3.2.2-bin-hadoop3.2/python/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.42854848, -0.32854385, -0.0182631 , -0.2265978 ,\n",
              "         0.00792303],\n",
              "       [ 0.42854848,  1.        , -0.17298035,  0.20603073, -0.03815852,\n",
              "         0.22725939],\n",
              "       [-0.32854385, -0.17298035,  1.        , -0.57640787, -0.37462089,\n",
              "        -0.45170047],\n",
              "       [-0.0182631 ,  0.20603073, -0.57640787,  1.        ,  0.70397453,\n",
              "         0.61110339],\n",
              "       [-0.2265978 , -0.03815852, -0.37462089,  0.70397453,  1.        ,\n",
              "         0.19199918],\n",
              "       [ 0.00792303,  0.22725939, -0.45170047,  0.61110339,  0.19199918,\n",
              "         1.        ]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.stat import Correlation\n",
        "\n",
        "matrix = Correlation.corr(final_data, 'Independent features')\n",
        "cor_np = matrix.collect()[0][matrix.columns[0]].toArray()\n",
        "cor_np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0eiZUdrAUKW"
      },
      "source": [
        "Obtener el valor del intercepto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRPAwuMDhGsQ",
        "outputId": "b04f0173-cd73-4dcd-bea9-ddde873ebcfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-173769.9227155356"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.intercept"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWm_ACuzAXhS"
      },
      "source": [
        "Los coeficientes por cada variable independiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmOSQXazhC4_",
        "outputId": "b23173a5-93cc-4bbc-95d1-16c0b9dda888"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DenseVector([-44971.9493, -1.2105, 6639.738, 108.4468, 15387.114, -78662.7525])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvVYUVYQAbst"
      },
      "source": [
        "Así como los p-values para determinar la transendencia de cada variable dentro del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvpGrjq1iEvM",
        "outputId": "a333c8b6-118e-431d-e408-9eb86275e259"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.0,\n",
              " 0.002742261743691632,\n",
              " 3.523048235209991e-05,\n",
              " 0.0,\n",
              " 6.661338147750939e-16,\n",
              " 0.04900845799491815]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.summary.pValues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz0Mb-N_AkKw"
      },
      "source": [
        "Obtener indicadores de desempeño como la $r^2$ ajustada, dado que es un problema multivariado. Que nos sirve para indicar el porcentaje de la variabilidad de la variable dependiente explicada por el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi-wb7QUifex",
        "outputId": "c1a3f3ae-3e80-4c3b-a7f0-1bc48de35f68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6321404714030512"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.summary.r2adj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5rpjApHA12V"
      },
      "source": [
        "Podemos realizar predicciones para evaluar el modelo obtenido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHIihH1RhJ-b",
        "outputId": "90df7fbc-d63f-467d-96fa-92adff1aa315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+------------------+\n",
            "|Independent features|selling_price|        prediction|\n",
            "+--------------------+-------------+------------------+\n",
            "|[2.0,1000.0,20.3,...|       500000| 641722.6632724255|\n",
            "|[2.0,1000.0,21.21...|       445000| 871067.4907851031|\n",
            "|[2.0,1600.0,13.96...|      1900000|1760665.7369542336|\n",
            "|[2.0,2136.0,22.5,...|       350000| 629055.9157200744|\n",
            "|[2.0,5000.0,0.0,2...|       679000| 923617.4918622139|\n",
            "|[2.0,5000.0,21.01...|       630000| 864897.6729820727|\n",
            "|[2.0,5000.0,21.21...|       570000| 866225.6205875105|\n",
            "|[2.0,5000.0,21.21...|       600000| 866225.6205875105|\n",
            "|[2.0,5500.0,26.8,...|      2125000|1503128.7539815935|\n",
            "|[2.0,10000.0,18.7...|       737000| 1202851.782968651|\n",
            "|[2.0,10000.0,19.0...|       450000| 618780.7713926989|\n",
            "|[2.0,15000.0,23.2...|       550000| 970826.0720435185|\n",
            "|[2.0,15000.0,24.3...|       810000| 983262.1843195695|\n",
            "|[2.0,20000.0,23.2...|       700000| 964773.7342965277|\n",
            "|[2.0,40000.0,10.7...|      1500000| 1940968.776891451|\n",
            "|[2.0,40000.0,17.5...|       500000| 905427.9097021874|\n",
            "|[2.0,44665.0,25.3...|       480000| 693089.2954687983|\n",
            "|[2.0,50000.0,20.1...|       260000| 940386.1997395628|\n",
            "|[2.0,60000.0,25.3...|       550000| 674526.7755987778|\n",
            "|[2.0,120000.0,21....|       250000| 480500.3496347894|\n",
            "+--------------------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction_result = model.evaluate(test_data)\n",
        "prediction_result.predictions.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzBuAmmiA7pk"
      },
      "source": [
        "Mostrar algunos indicadores de desempeño utiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdRto3yjhe_0",
        "outputId": "ecaf071b-9769-4dde-c585-a7657dc5e31d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(288271.49654614413, 225886958021.10565)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction_result.meanAbsoluteError, prediction_result.meanSquaredError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmz6gEjCCGLB"
      },
      "outputs": [],
      "source": [
        "from pyspark.mllib.tree import DecisionTree\n",
        "from pyspark.mllib.tree import DecisionTreeModel\n",
        "\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eINQssUpC729"
      },
      "outputs": [],
      "source": [
        "from pyspark.mllib.util import MLUtils\n",
        "\n",
        "data = MLUtils.loadLibSVMFile(sc, 'spark-3.2.2-bin-hadoop3.2/data/mllib/sample_libsvm_data.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_bVJzJ4YDZX"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo4frQjCFH26",
        "outputId": "dd6cf0b6-9e71-4552-ce01-f1f2cd019426"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[LabeledPoint(0.0, (692,[127,128,129,130,131,154,155,156,157,158,159,181,182,183,184,185,186,187,188,189,207,208,209,210,211,212,213,214,215,216,217,235,236,237,238,239,240,241,242,243,244,245,262,263,264,265,266,267,268,269,270,271,272,273,289,290,291,292,293,294,295,296,297,300,301,302,316,317,318,319,320,321,328,329,330,343,344,345,346,347,348,349,356,357,358,371,372,373,374,384,385,386,399,400,401,412,413,414,426,427,428,429,440,441,442,454,455,456,457,466,467,468,469,470,482,483,484,493,494,495,496,497,510,511,512,520,521,522,523,538,539,540,547,548,549,550,566,567,568,569,570,571,572,573,574,575,576,577,578,594,595,596,597,598,599,600,601,602,603,604,622,623,624,625,626,627,628,629,630,651,652,653,654,655,656,657],[51.0,159.0,253.0,159.0,50.0,48.0,238.0,252.0,252.0,252.0,237.0,54.0,227.0,253.0,252.0,239.0,233.0,252.0,57.0,6.0,10.0,60.0,224.0,252.0,253.0,252.0,202.0,84.0,252.0,253.0,122.0,163.0,252.0,252.0,252.0,253.0,252.0,252.0,96.0,189.0,253.0,167.0,51.0,238.0,253.0,253.0,190.0,114.0,253.0,228.0,47.0,79.0,255.0,168.0,48.0,238.0,252.0,252.0,179.0,12.0,75.0,121.0,21.0,253.0,243.0,50.0,38.0,165.0,253.0,233.0,208.0,84.0,253.0,252.0,165.0,7.0,178.0,252.0,240.0,71.0,19.0,28.0,253.0,252.0,195.0,57.0,252.0,252.0,63.0,253.0,252.0,195.0,198.0,253.0,190.0,255.0,253.0,196.0,76.0,246.0,252.0,112.0,253.0,252.0,148.0,85.0,252.0,230.0,25.0,7.0,135.0,253.0,186.0,12.0,85.0,252.0,223.0,7.0,131.0,252.0,225.0,71.0,85.0,252.0,145.0,48.0,165.0,252.0,173.0,86.0,253.0,225.0,114.0,238.0,253.0,162.0,85.0,252.0,249.0,146.0,48.0,29.0,85.0,178.0,225.0,253.0,223.0,167.0,56.0,85.0,252.0,252.0,252.0,229.0,215.0,252.0,252.0,252.0,196.0,130.0,28.0,199.0,252.0,252.0,253.0,252.0,252.0,233.0,145.0,25.0,128.0,252.0,253.0,252.0,141.0,37.0])),\n",
              " LabeledPoint(1.0, (692,[158,159,160,161,185,186,187,188,189,213,214,215,216,217,240,241,242,243,244,245,267,268,269,270,271,295,296,297,298,322,323,324,325,326,349,350,351,352,353,377,378,379,380,381,404,405,406,407,408,431,432,433,434,435,459,460,461,462,463,486,487,488,489,490,514,515,516,517,518,542,543,544,545,569,570,571,572,573,596,597,598,599,600,601,624,625,626,627,652,653,654,655,680,681,682,683],[124.0,253.0,255.0,63.0,96.0,244.0,251.0,253.0,62.0,127.0,251.0,251.0,253.0,62.0,68.0,236.0,251.0,211.0,31.0,8.0,60.0,228.0,251.0,251.0,94.0,155.0,253.0,253.0,189.0,20.0,253.0,251.0,235.0,66.0,32.0,205.0,253.0,251.0,126.0,104.0,251.0,253.0,184.0,15.0,80.0,240.0,251.0,193.0,23.0,32.0,253.0,253.0,253.0,159.0,151.0,251.0,251.0,251.0,39.0,48.0,221.0,251.0,251.0,172.0,234.0,251.0,251.0,196.0,12.0,253.0,251.0,251.0,89.0,159.0,255.0,253.0,253.0,31.0,48.0,228.0,253.0,247.0,140.0,8.0,64.0,251.0,253.0,220.0,64.0,251.0,253.0,220.0,24.0,193.0,253.0,220.0])),\n",
              " LabeledPoint(1.0, (692,[124,125,126,127,151,152,153,154,155,179,180,181,182,183,208,209,210,211,235,236,237,238,239,263,264,265,266,267,268,292,293,294,295,296,321,322,323,324,349,350,351,352,377,378,379,380,405,406,407,408,433,434,435,436,461,462,463,464,489,490,491,492,493,517,518,519,520,521,545,546,547,548,549,574,575,576,577,578,602,603,604,605,606,630,631,632,633,634,658,659,660,661,662],[145.0,255.0,211.0,31.0,32.0,237.0,253.0,252.0,71.0,11.0,175.0,253.0,252.0,71.0,144.0,253.0,252.0,71.0,16.0,191.0,253.0,252.0,71.0,26.0,221.0,253.0,252.0,124.0,31.0,125.0,253.0,252.0,252.0,108.0,253.0,252.0,252.0,108.0,255.0,253.0,253.0,108.0,253.0,252.0,252.0,108.0,253.0,252.0,252.0,108.0,253.0,252.0,252.0,108.0,255.0,253.0,253.0,170.0,253.0,252.0,252.0,252.0,42.0,149.0,252.0,252.0,252.0,144.0,109.0,252.0,252.0,252.0,144.0,218.0,253.0,253.0,255.0,35.0,175.0,252.0,252.0,253.0,35.0,73.0,252.0,252.0,253.0,35.0,31.0,211.0,252.0,253.0,35.0])),\n",
              " LabeledPoint(1.0, (692,[152,153,154,180,181,182,183,208,209,210,211,236,237,238,239,264,265,266,267,292,293,294,295,320,321,322,323,349,350,351,377,378,379,405,406,407,433,434,435,461,462,463,489,490,491,492,517,518,519,520,546,547,548,574,575,576,602,603,604,630,631,632,658,659,660,686,687,688],[5.0,63.0,197.0,20.0,254.0,230.0,24.0,20.0,254.0,254.0,48.0,20.0,254.0,255.0,48.0,20.0,254.0,254.0,57.0,20.0,254.0,254.0,108.0,16.0,239.0,254.0,143.0,178.0,254.0,143.0,178.0,254.0,143.0,178.0,254.0,162.0,178.0,254.0,240.0,113.0,254.0,240.0,83.0,254.0,245.0,31.0,79.0,254.0,246.0,38.0,214.0,254.0,150.0,144.0,241.0,8.0,144.0,240.0,2.0,144.0,254.0,82.0,230.0,247.0,40.0,168.0,209.0,31.0])),\n",
              " LabeledPoint(1.0, (692,[151,152,153,154,179,180,181,182,208,209,210,236,237,238,264,265,266,267,292,293,294,295,320,321,322,323,348,349,350,351,376,377,378,379,404,405,406,407,432,433,434,435,460,461,462,463,488,489,490,491,516,517,518,519,544,545,546,547,572,573,574,575,600,601,602,603,629,630,631,657,658,659,685,686,687],[1.0,168.0,242.0,28.0,10.0,228.0,254.0,100.0,190.0,254.0,122.0,83.0,254.0,162.0,29.0,254.0,248.0,25.0,29.0,255.0,254.0,103.0,29.0,254.0,254.0,109.0,29.0,254.0,254.0,109.0,29.0,254.0,254.0,109.0,29.0,255.0,254.0,109.0,29.0,254.0,254.0,109.0,29.0,254.0,254.0,63.0,29.0,254.0,254.0,28.0,29.0,254.0,254.0,28.0,29.0,254.0,254.0,35.0,29.0,254.0,254.0,109.0,6.0,212.0,254.0,109.0,203.0,254.0,178.0,155.0,254.0,190.0,32.0,199.0,104.0])),\n",
              " LabeledPoint(0.0, (692,[129,130,131,132,156,157,158,159,160,161,162,183,184,185,186,187,188,189,190,208,209,210,211,212,213,214,215,216,217,218,235,236,237,238,239,240,241,242,243,244,245,246,262,263,264,265,266,267,268,269,270,271,272,273,274,289,290,291,292,293,294,295,296,297,298,299,300,301,302,316,317,318,319,320,322,323,324,325,327,328,329,330,343,344,345,346,347,348,350,351,352,353,355,356,357,358,371,372,373,374,378,379,384,385,386,398,399,400,412,413,414,425,426,427,428,439,440,441,442,453,454,455,456,467,468,469,470,481,482,483,484,494,495,496,497,498,509,510,511,512,521,522,523,524,525,537,538,539,540,547,548,549,550,551,552,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,594,595,596,597,598,599,600,601,602,603,604,605,623,624,625,626,627,628,629,630,631,632,653,654,655,656,657,658],[64.0,253.0,255.0,63.0,96.0,205.0,251.0,253.0,205.0,111.0,4.0,96.0,189.0,251.0,251.0,253.0,251.0,251.0,31.0,16.0,64.0,223.0,244.0,251.0,251.0,211.0,213.0,251.0,251.0,31.0,80.0,181.0,251.0,253.0,251.0,251.0,251.0,94.0,96.0,251.0,251.0,31.0,92.0,253.0,253.0,253.0,255.0,253.0,253.0,253.0,95.0,96.0,253.0,253.0,31.0,92.0,236.0,251.0,243.0,220.0,233.0,251.0,251.0,243.0,82.0,96.0,251.0,251.0,31.0,80.0,253.0,251.0,251.0,188.0,96.0,251.0,251.0,109.0,96.0,251.0,251.0,31.0,96.0,240.0,253.0,243.0,188.0,42.0,96.0,204.0,109.0,4.0,12.0,197.0,251.0,31.0,221.0,251.0,253.0,121.0,36.0,23.0,190.0,251.0,31.0,48.0,234.0,253.0,191.0,253.0,31.0,44.0,221.0,251.0,251.0,12.0,197.0,251.0,31.0,190.0,251.0,251.0,251.0,96.0,251.0,251.0,31.0,190.0,251.0,251.0,113.0,40.0,234.0,251.0,219.0,23.0,190.0,251.0,251.0,94.0,40.0,217.0,253.0,231.0,47.0,191.0,253.0,253.0,253.0,12.0,174.0,253.0,253.0,219.0,39.0,67.0,236.0,251.0,251.0,191.0,190.0,111.0,72.0,190.0,191.0,197.0,251.0,243.0,121.0,39.0,63.0,236.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,251.0,188.0,94.0,27.0,129.0,253.0,251.0,251.0,251.0,251.0,229.0,168.0,15.0,95.0,212.0,251.0,211.0,94.0,59.0])),\n",
              " LabeledPoint(1.0, (692,[158,159,160,185,186,187,188,189,212,213,214,215,216,217,240,241,242,243,244,267,268,269,270,271,272,295,296,297,298,299,323,324,325,326,350,351,352,353,354,377,378,379,380,381,404,405,406,407,408,432,433,434,435,436,459,460,461,462,463,486,487,488,489,490,513,514,515,516,517,541,542,543,544,545,569,570,571,572,573,597,598,599,600,624,625,626,627,628,652,653,654,655,681,682,683],[121.0,254.0,136.0,13.0,230.0,253.0,248.0,99.0,4.0,118.0,253.0,253.0,225.0,42.0,61.0,253.0,253.0,253.0,74.0,32.0,206.0,253.0,253.0,186.0,9.0,211.0,253.0,253.0,239.0,69.0,254.0,253.0,253.0,133.0,142.0,255.0,253.0,186.0,8.0,149.0,229.0,254.0,207.0,21.0,54.0,229.0,253.0,254.0,105.0,152.0,254.0,254.0,213.0,26.0,112.0,251.0,253.0,253.0,26.0,29.0,212.0,253.0,250.0,149.0,36.0,214.0,253.0,253.0,137.0,75.0,253.0,253.0,253.0,59.0,93.0,253.0,253.0,189.0,17.0,224.0,253.0,253.0,84.0,43.0,235.0,253.0,126.0,1.0,99.0,248.0,253.0,119.0,225.0,235.0,49.0])),\n",
              " LabeledPoint(1.0, (692,[99,100,101,127,128,129,130,154,155,156,157,158,182,183,184,185,186,209,210,211,212,213,237,238,239,240,241,264,265,266,267,268,269,291,292,293,294,295,296,297,314,315,316,317,318,319,320,321,322,323,324,325,342,343,344,345,346,347,348,349,350,351,352,353,371,372,373,374,378,379,380,381,406,407,408,409,435,436,437,463,464,465,491,492,493,514,515,516,517,518,519,520,521,522,523,524,525,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,594,595,596,597,598,599,600,622,623,624,625],[166.0,222.0,55.0,197.0,254.0,218.0,5.0,29.0,249.0,254.0,254.0,9.0,45.0,254.0,254.0,174.0,2.0,4.0,164.0,254.0,254.0,85.0,146.0,254.0,254.0,254.0,85.0,101.0,245.0,254.0,254.0,254.0,85.0,97.0,248.0,254.0,204.0,254.0,254.0,85.0,12.0,59.0,98.0,151.0,237.0,254.0,254.0,109.0,35.0,254.0,254.0,85.0,41.0,216.0,254.0,254.0,239.0,153.0,37.0,4.0,32.0,254.0,254.0,85.0,7.0,44.0,44.0,30.0,32.0,254.0,254.0,96.0,19.0,230.0,254.0,174.0,197.0,254.0,110.0,197.0,254.0,85.0,197.0,253.0,63.0,37.0,54.0,54.0,45.0,26.0,84.0,221.0,84.0,21.0,31.0,162.0,78.0,6.0,41.0,141.0,244.0,254.0,254.0,248.0,236.0,254.0,254.0,254.0,233.0,239.0,254.0,138.0,23.0,167.0,254.0,254.0,254.0,254.0,229.0,228.0,185.0,138.0,138.0,138.0,138.0,138.0,138.0,44.0,113.0,254.0,254.0,254.0,179.0,64.0,5.0,32.0,209.0,183.0,97.0])),\n",
              " LabeledPoint(0.0, (692,[154,155,156,157,158,159,182,183,184,185,186,187,188,189,208,209,210,211,212,213,214,215,216,217,236,237,238,239,240,241,242,243,244,245,264,265,266,267,268,269,270,271,272,273,290,291,292,293,294,295,298,299,300,301,318,319,320,321,322,326,327,328,329,346,347,348,349,350,353,354,355,356,357,374,375,376,377,378,381,382,383,384,385,402,403,404,405,406,409,410,411,412,413,429,430,431,432,437,438,439,440,456,457,458,459,460,464,465,466,467,468,484,485,486,487,488,491,492,493,494,495,512,513,514,515,516,519,520,521,522,523,540,541,542,543,544,546,547,548,549,550,551,568,569,570,571,572,573,574,575,576,577,596,597,598,599,600,601,602,603,604,605,624,625,626,627,628,629,630,631,632,633,653,654,655,656,657,658,682,683,684,685,686],[53.0,255.0,253.0,253.0,253.0,124.0,180.0,253.0,251.0,251.0,251.0,251.0,145.0,62.0,32.0,217.0,241.0,253.0,251.0,251.0,251.0,251.0,253.0,107.0,37.0,251.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,107.0,166.0,251.0,251.0,253.0,251.0,96.0,148.0,251.0,253.0,107.0,73.0,253.0,253.0,253.0,253.0,130.0,110.0,253.0,255.0,108.0,73.0,251.0,251.0,251.0,251.0,109.0,251.0,253.0,107.0,202.0,251.0,251.0,251.0,225.0,6.0,129.0,251.0,253.0,107.0,150.0,251.0,251.0,251.0,71.0,115.0,251.0,251.0,253.0,107.0,253.0,251.0,251.0,173.0,20.0,217.0,251.0,251.0,253.0,107.0,182.0,255.0,253.0,216.0,218.0,253.0,253.0,182.0,63.0,221.0,253.0,251.0,215.0,84.0,236.0,251.0,251.0,77.0,109.0,251.0,253.0,251.0,215.0,11.0,160.0,251.0,251.0,96.0,109.0,251.0,253.0,251.0,137.0,150.0,251.0,251.0,251.0,71.0,109.0,251.0,253.0,251.0,35.0,130.0,253.0,251.0,251.0,173.0,20.0,110.0,253.0,255.0,253.0,98.0,150.0,253.0,255.0,253.0,164.0,109.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,251.0,35.0,93.0,241.0,253.0,251.0,251.0,251.0,251.0,216.0,112.0,5.0,103.0,253.0,251.0,251.0,251.0,251.0,124.0,251.0,225.0,71.0,71.0])),\n",
              " LabeledPoint(0.0, (692,[127,128,129,130,131,155,156,157,158,159,181,182,183,184,185,186,187,209,210,211,212,213,214,215,216,237,238,239,240,241,242,243,244,245,263,264,265,266,267,268,269,270,271,272,273,291,292,293,294,295,296,297,298,299,300,301,302,317,318,319,320,321,322,323,324,325,326,327,328,329,330,344,345,346,347,348,349,353,354,355,356,357,358,372,373,374,375,376,377,381,382,383,384,385,386,399,400,401,402,403,404,409,410,411,412,413,414,427,428,429,430,431,437,438,439,440,441,455,456,457,458,459,460,465,466,467,468,483,484,485,486,487,488,491,492,493,494,495,496,511,512,513,514,515,519,520,521,522,523,539,540,541,542,543,544,545,546,547,548,549,550,567,568,569,570,571,572,573,574,575,576,577,578,595,596,597,598,599,600,601,602,603,604,605,623,624,625,626,627,628,629,630,631,652,653,654,655,656,657,658],[73.0,253.0,227.0,73.0,21.0,73.0,251.0,251.0,251.0,174.0,16.0,166.0,228.0,251.0,251.0,251.0,122.0,62.0,220.0,253.0,251.0,251.0,251.0,251.0,79.0,79.0,231.0,253.0,251.0,251.0,251.0,251.0,232.0,77.0,145.0,253.0,253.0,253.0,255.0,253.0,253.0,253.0,253.0,255.0,108.0,144.0,251.0,251.0,251.0,253.0,168.0,107.0,169.0,251.0,253.0,189.0,20.0,27.0,89.0,236.0,251.0,235.0,215.0,164.0,15.0,6.0,129.0,251.0,253.0,251.0,35.0,47.0,211.0,253.0,251.0,251.0,142.0,37.0,251.0,251.0,253.0,251.0,35.0,109.0,251.0,253.0,251.0,251.0,142.0,11.0,148.0,251.0,253.0,251.0,164.0,11.0,150.0,253.0,255.0,211.0,25.0,11.0,150.0,253.0,255.0,211.0,25.0,140.0,251.0,251.0,253.0,107.0,37.0,251.0,251.0,211.0,46.0,190.0,251.0,251.0,253.0,128.0,5.0,37.0,251.0,251.0,51.0,115.0,251.0,251.0,253.0,188.0,20.0,32.0,109.0,129.0,251.0,173.0,103.0,217.0,251.0,251.0,201.0,30.0,73.0,251.0,251.0,251.0,71.0,166.0,253.0,253.0,255.0,149.0,73.0,150.0,253.0,255.0,253.0,253.0,143.0,140.0,251.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,251.0,230.0,61.0,190.0,251.0,251.0,253.0,251.0,251.0,251.0,251.0,242.0,215.0,55.0,21.0,189.0,251.0,253.0,251.0,251.0,251.0,173.0,103.0,31.0,200.0,253.0,251.0,96.0,71.0,20.0]))]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEw7hMHsatv5"
      },
      "outputs": [],
      "source": [
        "numClasses = 2\n",
        "categoricalFeaturesInfo = {}\n",
        "impurity = \"gini\"\n",
        "\n",
        "model = DecisionTree.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo,\n",
        "  impurity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmTnplvuETu_",
        "outputId": "1e4dcb6e-9fc3-4a90-8dd2-41cf503fb027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error = 0.06060606060606061\n",
            "Learned classification tree model:\n",
            "DecisionTreeModel classifier of depth 1 with 3 nodes\n",
            "  If (feature 406 <= 22.0)\n",
            "   Predict: 0.0\n",
            "  Else (feature 406 > 22.0)\n",
            "   Predict: 1.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(testData.map(lambda x: x.features))\n",
        "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
        "testErr = labelsAndPredictions.filter(\n",
        "    lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
        "print('Test Error = ' + str(testErr))\n",
        "print('Learned classification tree model:')\n",
        "print(model.toDebugString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AW9M4gSrviR",
        "outputId": "5de512de-a8ce-4bcc-a778-ec97498bfbd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: ./bin/pyspark: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!./bin/pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "od6iDkJhIVm8",
        "outputId": "dafb479d-2c6a-4470-8c13-e990db8cd07f"
      },
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-e42e5d6bf58b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"myDecisionTreeClassificationModel.dt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msameModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"myDecisionTreeClassificationModel.dt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop3.2/python/pyspark/mllib/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sc, path)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a string, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop3.2/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop3.2/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o310.save.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/content/myDecisionTreeClassificationModel.dt/metadata already exists\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:299)\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:964)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:962)\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1578)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1578)\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1564)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1564)\n\tat org.apache.spark.mllib.tree.model.DecisionTreeModel$SaveLoadV1_0$.save(DecisionTreeModel.scala:227)\n\tat org.apache.spark.mllib.tree.model.DecisionTreeModel.save(DecisionTreeModel.scala:127)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
          ]
        }
      ],
      "source": [
        "model.save(sc, \"myDecisionTreeClassificationModel.dt\")\n",
        "sameModel = DecisionTreeModel.load(sc, \"myDecisionTreeClassificationModel.dt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "kbRRaZlBt6Nh",
        "h-buZtUBtnOp",
        "ikvKjBuY6e7-",
        "7_zMjiAbClef",
        "MHhiL2rneKF5",
        "wJ4qq4PRBWK3"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
